\section{Introduction}
\label{sec:introduction}
% Mention scientific context/field, problem statement, research gap and candidate (sub) research question(s). 
Machine learning (ML) is increasingly being utilized in almost all fields of study and is found to be more efficient and effective in terms of performance compared to the traditional ways of forecasting, classification and more. To achieve maximum accuracy and forecasting using machine learning, ML models need to be trained, validated and tested on a large amount of data. The data that is used to train, validate and  the machine learning model could be sensitive, having personal information and hence, could lead to the undesirable issue of privacy concerns. An EU law known as the General Data Protection Law (GDPR) establishes standards for the gathering, use, and processing of personal data of EU citizens. In general, processing personal information is banned unless it is specifically permitted by law, or the data subject has given consent or is anonymized or synthetic data\cite{Einwilligung}. To overcome the issue of privacy and gain maximum accuracy, there is a desire to use ML/AI approaches data to transform sensitive data into valuable information while adhering to the consent of the parties involved or use synthetic data \cite{soykan2022survey}. \\
Even though anonymization methods can help safeguard private information, could also impact the ML model's performance. If the k-anonymization hierarchy is properly used in the anonymization process of the data, the ML model, which is trained on the k-anonymized data in higher accuracy to synthetic data and results in similar accuracy to the model trained on the original data\cite{oprescu2022energy}. Further \cite{hoyos2020contribution} found that some ML models are more suitable with k-anonymised data and perform better than others. While research on machine learning algorithms and PETs has been done, However, there is a limitation in researching the effect of different PETs on ML models \cite{hoyos2020contribution}. Hence, to best our knowledge it's unclear or there is shortage of studies on how privacy enhancing techniques will ultimately affect the usefulness of data and ultimately the performance of the ML model accuracy; therefore, it's critical to conduct an empirical and comparative analysis of this effect.\\
\begin{center}
    \textbf{The impact of anonymization techniques on machine learning model's accuracy?}
\end{center}
This paper tries to broaden the research by \cite{oprescu2022energy, hoyos2020contribution} by including more PETs and more ML models. Both suggested that it is worth of studying the impact of PETs on ML accuracy. Moreover \cite{rodriguez2020contribution} point out that the real impact of privacy protection systems on the usefulness of data is not yet evident. Hence, additional comparative research will be performed to measuring the impact of anonymization techniques on machine learning accuracy.\\  
The  dataset  \href{https://archive.ics.uci.edu/ml/datasets/Early+stage+diabetes+risk+prediction+dataset.} {Early Stage Diabetes}, which is publicly available on the UCI Machine leaning Repository ill be utilized to assess the  methodology. This dataset are used in different generalization and anonymization researches \cite{oprescu2022energy,goldsteen2022anonymizing,Jaime}




